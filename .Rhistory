(1:maxTableIndex)[tableRestaurantAllocation==indexRestaurant]
currentTable = tableAllocation[indexCustomerGlobal] # get the current table
currentDish  = dishAllocation[indexCustomerGlobal] # get the current dish
nPeopleAtTable[currentTable] = nPeopleAtTable[currentTable] - 1
if(nPeopleAtTable[currentTable] == 0) { # free the table
nFreeTables = nFreeTables +1
freeTables = c(currentTable,freeTables)
tableRestaurantAllocation[currentTable] = -1
nTablesInRestaurant[indexRestaurant] = nTablesInRestaurant[indexRestaurant] - 1
nTables = nTables - 1
tablesValues[currentTable] = -1
}
indecesPossibleTables = (tablesValues[indecesTablesInRestaurant] ==
dishAllocation[indexCustomerGlobal])
if(sum(indecesPossibleTables)==0){
# if no tables in the restaurant is serving the observed dish
newTableAllocation = -1 # open a new table
} else {
# if there are tables in the restaurant serving the observed dish
possibleTables = c(indecesTablesInRestaurant[indecesPossibleTables],-1)
nTablesServingCurrentDish =
sum(tablesValues == dishAllocation[indexCustomerGlobal])
probs = prob_Table_insample_j(model="HPYP")
newTableAllocation = sample(possibleTables, 1, replace = F, prob = probs)
}
if(newTableAllocation < 0) {
nTables = nTables + 1
if(nFreeTables > 0) { # pick the first free table
newTableAllocation = freeTables[1]
freeTables = freeTables[-1]
nFreeTables = nFreeTables - 1
nPeopleAtTable[newTableAllocation] = 1
nTablesInRestaurant[indexRestaurant] =
nTablesInRestaurant[indexRestaurant] + 1
tablesValues[newTableAllocation] = dishAllocation[indexCustomerGlobal]
} else { # create a new table
nTablesInRestaurant[indexRestaurant] =
nTablesInRestaurant[indexRestaurant] + 1
maxTableIndex = maxTableIndex + 1
newTableAllocation = maxTableIndex
nPeopleAtTable = c(nPeopleAtTable,1)
tablesValues = c(tablesValues,dishAllocation[indexCustomerGlobal])
}
# assign the table to the restaurant
tableRestaurantAllocation[newTableAllocation] = indexRestaurant
} else{ # the sampled table is already occupied in the restaurant -->
# just update the relevant quantities
nPeopleAtTable[newTableAllocation] =
nPeopleAtTable[newTableAllocation] + 1
}
tableAllocation[indexCustomerGlobal] = newTableAllocation
tableAllocationAcrossGibbs[r,indexCustomerGlobal] = newTableAllocation
indexCustomerGlobal = indexCustomerGlobal + 1
}
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
# Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec = integer(J)
K_j_vec = unique(X_ji_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(X_ji_vec[lab_ji_vec]))
}
K_j_vec
cum_K_j_vec = cumsum(K_j_vec)
# Empirical pEPPF unnormalized
emp_pEPPF_un = matrix(0, nrow=D, ncol=J)
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
for (d in Xstar_d_vec){
emp_pEPPF_un[d,j] = sum(X_ji_vec[lab_ji_vec]==d)
}
}
emp_pEPPF_un
emp_pEPPF_un/n
# Numerically 0 lowerbound hyperpar
epsilon = 1e-5
# Numerically infinite upperbound hyperpar
Max_val = 1e10
# MCMC quantities
nGibbsUpdates             = 2e4
tableAllocationAcrossGibbs = matrix(0,nrow = nGibbsUpdates, ncol = n)
# tables to which customers are allocated across Gibbs
set.seed(123)
##### INITIALIZATION
nRest                     = J
nObs                      = n
nDishes                   = D  # number of dishes served in the franchise
dishAllocation            = X_ji_vec
# allocation of customers to dishes -->
# dish indexes are global (across the franchise)
tableRestaurantAllocation = rep(1:J, times = I_j_vec)
# allocation of the table to the restaurant it is fixed across mcmc in hssp
# (not fixed in nested variations)
#####
if(FALSE){
##### INITIALIZATION TO ALL DIFFERENT TABLES (and some double notation)
tableAllocation           = 1:nObs
tablesValues              = dishAllocation
# dish served at each table in the franchise
nPeopleAtTable            = rep(1,n)
# people sitting at each table
nTables                   = n
# number of occupied tables in the franchise
maxTableIndex             = n
# max table index (nTables + nFreeTables = maxTableIndex)
nTablesInRestaurant       = I_j_vec
# contains only the number of occupied tables in each restaurant
observationDishAllocation = X_ji_vec
# how many people are eating a certain dish
###
nFreeTables = 0
freeTables = c() # indices of free tables CONSIDER USING A STACK
} else if (TRUE){
##### INITIALIZATION TO ALL THE SAME TABLE IF SAME DISH AND POPULATION
tableAllocation           = integer(n)
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
past_K_j_vec = 0
if(j!=1){
lab_ji_vec   = lab_ji_vec+cum_I_j_vec[j-1]
past_K_j_vec = cum_K_j_vec[j-1]
}
tableAllocation[lab_ji_vec] = X_ji_vec[lab_ji_vec] + past_K_j_vec
}
# allocation of customers to tables -->
# table indexes are global (across the franchise)
nTables                   = max(tableAllocation)
# number of occupied tables in the franchise
maxTableIndex             =  nTables
# max table index (nTables + nFreeTables = maxTableIndex)
tablesValues              = integer(nTables)
for(tab_lab in 1:nTables){
tablesValues[tab_lab] = unique(X_ji_vec[tableAllocation == tab_lab])
}
# dish served at each table in the franchise
nPeopleAtTable            = integer(nTables)
for(tab_lab in 1:nTables){
nPeopleAtTable[tab_lab] = sum(tableAllocation==tab_lab)
}
# people sitting at each table
nTablesInRestaurant       = K_j_vec
# contains only the number of occupied tables in each restaurant
observationDishAllocation = integer(nDishes)
for(lab_dish in 1:nDishes){
observationDishAllocation[lab_dish] = sum(X_ji_vec==lab_dish)
}
# how many people are eating a certain dish
###
nFreeTables = 0
freeTables = c() # indices of free tables CONSIDER USING A STACK
}
# in the following nTables will be the total number of tables,
# with some of them that might be free, while nTablesInRestaurant
# will contain only the number of occupied tables in each restaurant
# RANDOM HYPER-PARAMETERS DIFFERENT ACROSS POPULATIONS
# hyperparameters of Gamma distribution of \theta_j j = 0, 1, ..., J
shape_theta = 1
rate_theta  = 1
# Hyperparameters of Beta distribution of \sigma_j j = 0, 1, ..., J
a_sigma = 1
b_sigma = 1
# Adaptive Metropolis quantities
ada_step   = 50
ada_thresh = 0.44
r_ada      = 0
niter_MH   = 5 # Number of MH iterations used to update hyperparameters
# in each Gibbs iteration
# Quantities for adaptive Metropolis quantities
Prop_sd_logit_sig_j    = rep(0.01, J+1)
Move_sigma_j_out       = matrix(nrow=J+1, ncol=nGibbsUpdates)
Prop_sd_log_theta_j    = rep(0.01, J+1)
Move_theta_j_out       = matrix(nrow=J+1, ncol=nGibbsUpdates)
##### INITIALIZATION OF HYPERPARAMETERS WITH THEIR PRIOR MEANS
theta_vec = rep(shape_theta/rate_theta, nRest)
sigma_vec = rep(a_sigma/(a_sigma+b_sigma), nRest)
theta0  = shape_theta/rate_theta
sigma0  = a_sigma/(a_sigma+b_sigma)
### Gibbs Sampler (past tables)
r=1
indexRestaurant=1
indexCustomerRestaurant=1
indecesTablesInRestaurant =
(1:maxTableIndex)[tableRestaurantAllocation==indexRestaurant]
currentTable = tableAllocation[indexCustomerGlobal] # get the current table
currentDish  = dishAllocation[indexCustomerGlobal] # get the current dish
indexCustomerGlobal = 1
indecesTablesInRestaurant =
(1:maxTableIndex)[tableRestaurantAllocation==indexRestaurant]
currentTable = tableAllocation[indexCustomerGlobal] # get the current table
currentDish  = dishAllocation[indexCustomerGlobal] # get the current dish
nPeopleAtTable[currentTable] = nPeopleAtTable[currentTable] - 1
nPeopleAtTable
nPeopleAtTable[currentTable]
if(nPeopleAtTable[currentTable] == 0) { # free the table
nFreeTables = nFreeTables +1
freeTables = c(currentTable,freeTables)
tableRestaurantAllocation[currentTable] = -1
nTablesInRestaurant[indexRestaurant] = nTablesInRestaurant[indexRestaurant] - 1
nTables = nTables - 1
tablesValues[currentTable] = -1
}
indecesPossibleTables = (tablesValues[indecesTablesInRestaurant] ==
dishAllocation[indexCustomerGlobal])
indecesPossibleTables
tablesValues
indecesTablesInRestaurant
tableAllocation
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
theta0
sigma0
nDishes
nTables
theta_vec
sigma_vec
nTables
I_j_vec
prob_new_species_vec
rSamples =rgamma(1000, shape=shashape_theta, rate=rate_theta)
# RANDOM HYPER-PARAMETERS DIFFERENT ACROSS POPULATIONS
# hyperparameters of Gamma distribution of \theta_j j = 0, 1, ..., J
shape_theta = 1
rate_theta  = 1
# Hyperparameters of Beta distribution of \sigma_j j = 0, 1, ..., J
a_sigma = 1
b_sigma = 1
rSamples =rgamma(1000, shape=shashape_theta, rate=rate_theta)
rSamples =rgamma(1000, shape=shape_theta, rate=rate_theta)
mean(rSamples)
mean(rSamples); shape_theta/rate_theta
var(rSamples)
## Check
# rSamples =rgamma(1000, shape=shape_theta, rate=rate_theta)
# mean(rSamples); shape_theta/rate_theta
# var(rSamples)
rSamples =rbeta(1000, shape1=a_sigma, rate=b_sigma)
## Check
# rSamples =rgamma(1000, shape=shape_theta, rate=rate_theta)
# mean(rSamples); shape_theta/rate_theta
# var(rSamples)
rSamples =rbeta(1000, shape1=a_sigma, shape2=b_sigma)
mean(rSamples)
a_sigma/(a_sigma+b_sigma)
print(Error)
##### INITIALIZATION HSSP
initHSSP <- function(J,
# number of population
Data_vec,
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
model ="HPYP",
# model
shape_theta,
# common shape of theta_0, ..., theta_J gamma prior
rate_theta,
# common rate of theta_0, ..., theta_J gamma prior
a_sigma,
# first hyper of sigma_0, ..., sigma_J beta prior
b_sigma,
# second hyper of sigma_0, ..., sigma_J beta prior
tablesInit = c("equal", "separate", "manual", "random")
# initialization strategy for tables
){
# Check if the dishes are labelled in order of arrival
uniDish = unique(Data_vec)
if(! uniDish= sort(uniDish)){
uniDish
unique(Data_vec)
I_j_vec
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
K_j_vec
cum_K_j_vec = cumsum(K_j_vec)
}
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
return(K_j_vec=K_j_vec, cum_K_j_vec = cumsum(K_j_vec))
}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
I_j_vec
K_j_vec_fct
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
return(K_j_vec=K_j_vec, cum_K_j_vec = cumsum(K_j_vec))
}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
cum_K_j_vec = cumsum(K_j_vec
return(K_j_vec, cum_K_j_vec)
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
cum_K_j_vec = cumsum(K_j_vec)
return(K_j_vec, cum_K_j_vec)
}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
cum_K_j_vec = cumsum(K_j_vec)
return(list(K_j_vec,
cum_K_j_vec = cumsum(K_j_vec)
))
}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
cum_K_j_vec = cumsum(K_j_vec)
return(list(K_j_vec=K_j_vec,
cum_K_j_vec = cumsum(K_j_vec)
))
}
### Compute the numbers of different species within pop (K_j_vec) and
### their cumulative (cum_K_j_vec)
K_j_vec_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J = length(I_j_vec)
K_j_vec = integer(J)
K_j_vec = unique(Data_vec[1:I_j_vec[1]])
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
K_j_vec[j] = length(unique(Data_vec[lab_ji_vec]))
}
cum_K_j_vec = cumsum(K_j_vec)
return(list(K_j_vec=K_j_vec,
cum_K_j_vec = cumsum(K_j_vec)
))
}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
# Empirical pEPPF unnormalized
emp_pEPPF_un = matrix(0, nrow=D, ncol=J)
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
for (d in Xstar_d_vec){
emp_pEPPF_un[d,j] = sum(X_ji_vec[lab_ji_vec]==d)
}
}
emp_pEPPF_un
emp_pEPPF_un/n
### Compute the empirical pEPPF unnormalized
emp_pEPPF_un_fct <- function(
I_j_vec,
# number of observation in each population
Data_vec
# vector of data ordered by groups i.e.,
# X_{1,1}, ..., X_{I_1, 1}, ...., X_{1,J}, ..., X_{I_J, J}
){
J            = length(I_j_vec)
Xstar_d_vec  = unique(Data_vec)
D            = length(Xstar_d_vec)
emp_pEPPF_un = matrix(0, nrow=D, ncol=J)
for(j in 1:J){
lab_ji_vec = 1:I_j_vec[j]
if(j!=1){lab_ji_vec = lab_ji_vec+cum_I_j_vec[j-1]}
for (d in Xstar_d_vec){
emp_pEPPF_un[d,j] = sum(X_ji_vec[lab_ji_vec]==d)
}
}
return(emp_pEPPF_un)
}
emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
emp_pEPPF_un/n
