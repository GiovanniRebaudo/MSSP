log_1_sigma_prop = log(1-sigma_prop)
# Acc_prob_theta is on the logarithmic scale (consider Jacobian)
# Prior and Jacobian part
Acc_prob_sigma = a_sigma*(log_sigma_prop - log_sigma_old)+
b_sigma*(log_1_sigma_prop - log_1_sigma_old)
# Likelihood part (it can be made slightly more effiecient TBD)
indecesTablesInRestaurant =
(1:maxTableIndex)[tableRestaurantAllocation==indexRestaurant]
q_j_vec = nPeopleAtTable[indecesTablesInRestaurant]
Acc_prob_sigma = Acc_prob_sigma +
ell_j *(lgamma(1 - sigma_old) - lgamma(1 - sigma_prop))+
sum(lgamma(q_j_vec - sigma_prop) + lgamma(q_j_vec - sigma_old))+
sum(log(theta_old + vec_1_to_ell_j_1 * sigma_prop) -
log(theta_old + vec_1_to_ell_j_1 * sigma_old))
# End Likelihood part
move_sigma                = (log(runif(1)) < Acc_prob_sigma)
if(move_sigma){
sigma_old       = sigma_prop
log_1_sigma_old = log(1-sigma_old)
logit_sigma_old = log_sigma_old-log_1_sigma_old # logit function
}
} else {
move_sigma = FALSE
}
sigma_vec[indexRestaurant] = sigma_old
# Save acceptance if is the last iteration of MH
if (iter_MH == niter_MH){
Move_theta_j_out[indexRestaurant, r] = move_theta
Move_sigma_j_out[indexRestaurant, r] = move_sigma
}
}
}
# End MH within Gibbs step for hyperparameters
# Update proposal adaptive MH steps
if(r%%ada_step == 0){
r_ada                    = r_ada + ada_step
ada_delta                = min(0.01, 1/sqrt(r))
seq_ada_step             = (r_ada-ada_step):r_ada
# (Ada)
# Update proposal for \sigma_j, j = 0, 1, ..., J
Accept_sigma_j      = apply(Move_sigma_j_out[,seq_ada_step], 1, mean)
Dec_which_sigma_j   = Accept_sigma_j < ada_thresh
Prop_sd_logit_sig_j = ifelse(Dec_which_sigma_j,
exp(log(Prop_sd_logit_sig_j) - ada_delta),
exp(log(Prop_sd_logit_sig_j) + ada_delta))
# Update proposal for \theta_j, j = 0, 1, ..., J
Accept_theta_j      = apply(Move_theta_j_out[,seq_ada_step], 1, mean)
Dec_which_theta_j   = Accept_theta_j < ada_thresh
Prop_sd_log_theta_j = ifelse(Dec_which_theta_j,
exp(log(Prop_sd_log_theta_j) - ada_delta),
exp(log(Prop_sd_log_theta_j) + ada_delta))
}
# End Update proposal adaptive MH steps
}
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
# Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un =emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
round(emp_pEPPF_un/n,2) # empirical pEPPF
# Numerically 0 lowerbound hyperpar
epsilon = 1e-5
# Numerically infinite upperbound hyperpar
Max_val = 1e10
# MCMC quantities
nGibbsUpdates             = 2e3 #2e4
tableAllocationAcrossGibbs = matrix(0,nrow = nGibbsUpdates, ncol = n)
# tables to which customers are allocated across Gibbs
set.seed(123)
# RANDOM HYPER-PARAMETERS DIFFERENT ACROSS POPULATIONS
# hyperparameters of Gamma distribution of \theta_j j = 0, 1, ..., J
shape_theta = 1
rate_theta  = 1
# Hyperparameters of Beta distribution of \sigma_j j = 0, 1, ..., J
a_sigma = 1
b_sigma = 1
# Adaptive Metropolis quantities
ada_step   = 50
ada_thresh = 0.44
r_ada      = 0
niter_MH   = 1 # Number of MH iterations used to update hyperparameters
# in each Gibbs iteration
# Quantities for adaptive Metropolis quantities
Prop_sd_logit_sig_j    = rep(0.01, J+1)
Move_sigma_j_out       = matrix(nrow=J+1, ncol=nGibbsUpdates)
Prop_sd_log_theta_j    = rep(0.01, J+1)
Move_theta_j_out       = matrix(nrow=J+1, ncol=nGibbsUpdates)
#### Initialization
init_all = initHSSP_fct(I_j_vec     = I_j_vec,
Data_vec    = X_ji_vec,
tablesInit  = "equal", # "separate"
model       = "HPYP",
shape_theta = shape_theta,
rate_theta  = rate_theta,
a_sigma     = a_sigma,
b_sigma     = b_sigma)
# Initialized values and quantities named for MCMC
theta_vec                 = init_all$theta_vec
sigma_vec                 = init_all$sigma_vec
theta0                    = init_all$theta0
sigma0                    = init_all$sigma0
nObs                      = init_all$nObs
nRest                     = init_all$nRest
nDishes                   = init_all$nDishes
dishAllocation            = init_all$dishAllocation
tablesValues              = init_all$tablesValues
tableAllocation           = init_all$tableAllocation
tableRestaurantAllocation = init_all$tableRestaurantAllocation
nPeopleAtTable            = init_all$nPeopleAtTable
nTables                   = init_all$nTables
maxTableIndex             = init_all$maxTableIndex
nTablesInRestaurant       = init_all$nTablesInRestaurant
observationDishAllocation = init_all$observationDishAllocation
nFreeTables               = init_all$nFreeTables
freeTables                = init_all$freeTables
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
theta0
nDishes
sigma0
nDishes
nTablesInRestaurant
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
nTablesInRestaurant
prob_new_species_vec
prob_new_group_DP
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
colsum(prob_new_species_vec)
# tableAllocationAcrossGibbs = matrix(0,nrow = nGibbsUpdates, ncol = n)
prob_new_species = matrix(0,nrow = nGibbsUpdates, ncol = length(I_j_vec))
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
set.seed(123)
# RANDOM HYPER-PARAMETERS DIFFERENT ACROSS POPULATIONS
# hyperparameters of Gamma distribution of \theta_j j = 0, 1, ..., J
shape_theta = 1
rate_theta  = 1
# Hyperparameters of Beta distribution of \sigma_j j = 0, 1, ..., J
a_sigma     = 1
b_sigma     = 1
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
burnin     = min(nGibbsUpdates/2,500)
colsum(prob_new_species_vec)
colSums(prob_new_species_vec)
prob_new_species_vec
colSums(prob_new_species)
colMeans(prob_new_species)
colMeans(prob_new_species)
dataframe(prob_new_species)
data.frame(prob_new_species)
data.frame(cbind(1:nGibbsUpdates,prob_new_species))
ggplot(data = data.frame(cbind(1:nGibbsUpdates,prob_new_species)), aes(x = X1)) +
geom_line(aes(y = X2)) +
geom_line(aes(y = X3)) +
geom_line(aes(y = X4)) +
labs(y = "")
ggplot(data = data.frame(cbind(1:nGibbsUpdates,prob_new_species)), aes(x = X1)) +
geom_line(aes(y = X2)) +
geom_line(aes(y = X3),col=2) +
geom_line(aes(y = X4),col=3) +
labs(y = "")
ggplot(data = data.frame(cbind(1:nGibbsUpdates,prob_new_species)), aes(x = X1)) +
geom_line(aes(y = X2)) +
geom_line(aes(y = X3),col=2) +
geom_line(aes(y = X4),col=3) +
labs(x="iter", y = "")
# Optimal arm
which.max(colMeans(prob_new_species[burnin:nGibbsUpdates,]))
# Check predictive probabilities
ggplot(data = data.frame(cbind(1:nGibbsUpdates,prob_new_species)), aes(x = X1)) +
geom_line(aes(y = X2), col=1) +
geom_line(aes(y = X3), col=2) +
geom_line(aes(y = X4), col=3) +
labs(x="iter", y = "")
HPYP_MCMC_fct(
seed       = 123,
# seed to be fixed
Hyperprior = F,
# learn hyperpar via full Bayes if  Hyperprior==T
niter_MH   = 5,
# number of MH iterations for hyperpar update within each steps
I_j_vec = I_j_vec,
Data_vec = X_ji_vec
)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
# Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un =emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
round(emp_pEPPF_un/n,2) # empirical pEPPF
#### Initialization Gibbs
init_all = initHSSP_fct(I_j_vec     = I_j_vec,
Data_vec    = X_ji_vec,
tablesInit  = "equal", # "separate"
model       = "HPYP",
shape_theta = shape_theta,
rate_theta  = rate_theta,
a_sigma     = a_sigma,
b_sigma     = b_sigma)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
I_j_vec
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
##### Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
### Preliminaries and data summaries
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un =emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
round(emp_pEPPF_un/n,2) # empirical pEPPF
#### Initialization Gibbs
init_all = initHSSP_fct(I_j_vec     = I_j_vec,
Data_vec    = X_ji_vec,
tablesInit  = "equal", # "separate"
model       = "HPYP",
shape_theta = 1,
rate_theta  = 1,
a_sigma     = 1,
b_sigma     = 1)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
theta_vec
init_all$theta_vec
theta_vec
init_all$sigma_vec
theta0
init_all$theta0
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
prob_Table_insample_j
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
##### Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
### Preliminaries and data summaries
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un =emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
round(emp_pEPPF_un/n,2) # empirical pEPPF
#### Initialization Gibbs
init_all = initHSSP_fct(I_j_vec     = I_j_vec,
Data_vec    = X_ji_vec,
tablesInit  = "equal", # "separate"
model       = "HPYP",
shape_theta = 1,
rate_theta  = 1,
a_sigma     = 1,
b_sigma     = 1)
output = HPYP_MCMC_fct(
seed           = 123,
# seed to be fixed
Hyperprior     = F,
# learn hyperpar via full Bayes if  Hyperprior==T
niter_MH       = 5,
# number of MH iterations for hyperpar update within each steps
I_j_vec        = I_j_vec,
Data_vec       = X_ji_vec,
nGibbsUpdates  = 2e4,
theta_vec      = init_all$theta_vec,
sigma_vec      = init_all$sigma_vec,
theta0         = init_all$theta0,
sigma0         = init_all$sigma0
)
# Codes accompanying "Entropy Regularization in Probabilistic Clustering"
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(salso)
library(ggplot2)
# Load functions
source("MSSP_fcts.R")
Save_Plot = FALSE
set.seed(123)
##### Multivariate species simulations/truth
J           = 3 # Number of populations
I_j_vec     = rep(100,J)
cum_I_j_vec = cumsum(I_j_vec)
# I_j_vec = (I_1, ...,I_J) vector of sample size in different population
n           = sum(I_j_vec) # tot number of observations
# X_ji_vec = integer(n)
# Values of all observations (X_{1,1},...,X_{1,I_1},...,X_{J,1},...,X_{J,I_J})
X_ji_vec = c(rep(1,I_j_vec[1]), # X_1i_vec = (X_{1,1},...,X_{1,I_1})
rep(c(rep(2,15),rep(3,20),rep(1,15)),2), # X_2i_vec
rep(1:10,10)) # X_3i_vec
Xstar_d_vec = unique(X_ji_vec) # observed dishes (dishes=species)
D           = length(Xstar_d_vec) # overall number of dishes
# Check
if (n != length(X_ji_vec)){print("error: n != length(X_ji_vec)"); stop()}
if (sum(Xstar_d_vec != 1:D)){
print("error: labels of dish are not ordered"); stop()}
if (J != length(I_j_vec)){print("error: J != length(I_j_vec)"); stop()}
### Preliminaries and data summaries
# Truth of in sample species
table(X_ji_vec) # overall species freq. (n_{.,d})_{d=1}^{D}
# Numbers of different species within pop
K_j_vec_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un =emp_pEPPF_un_fct(I_j_vec=I_j_vec, Data_vec=X_ji_vec)
emp_pEPPF_un
round(emp_pEPPF_un/n,2) # empirical pEPPF
#### Initialization Gibbs
init_all = initHSSP_fct(I_j_vec     = I_j_vec,
Data_vec    = X_ji_vec,
tablesInit  = "equal", # "separate"
model       = "HPYP",
shape_theta = 1,
rate_theta  = 1,
a_sigma     = 1,
b_sigma     = 1)
theta_vec      = init_all$theta_vec
output = HPYP_MCMC_fct(
seed           = 123,
# seed to be fixed
Hyperprior     = F,
# learn hyperpar via full Bayes if  Hyperprior==T
niter_MH       = 5,
# number of MH iterations for hyperpar update within each steps
I_j_vec        = I_j_vec,
Data_vec       = X_ji_vec,
nGibbsUpdates  = 2e4,
theta_vec      = init_all$theta_vec,
sigma_vec      = init_all$sigma_vec,
theta0         = init_all$theta0,
sigma0         = init_all$sigma0
)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
nGibbsUpdates = length(output)
burnin     = min(nGibbsUpdates/2,500)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
nGibbsUpdates = nrow(output)
burnin        = min(nGibbsUpdates/2,500)
# Check predictive probabilities
ggplot(data = data.frame(cbind(1:nGibbsUpdates,output)), aes(x = X1)) +
geom_line(aes(y = X2), col=1) +
geom_line(aes(y = X3), col=2) +
geom_line(aes(y = X4), col=3) +
labs(x="iter", y = "")
# Choose the optimal arm
which.max(colMeans(output[burnin:nGibbsUpdates,]))
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_fcts.R", echo=TRUE)
5+5
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
emp_pEPPF_un
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
nGibbsUpdates
burnin
nGibbsUpdates
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
# Check predictive probabilities
ggplot(data = data.frame(cbind(1:nGibbsUpdates,output)), aes(x = X1)) +
geom_line(aes(y = X2), col=1) +
geom_line(aes(y = X3), col=2) +
geom_line(aes(y = X4), col=3) +
labs(x="iter", y = "")
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
colMeans(output[burnin:nGibbsUpdates,]
colMeans(output[burnin:nGibbsUpdates,])
colMeans(output[burnin:nGibbsUpdates,])
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
Move_theta_j_out
source("~/Library/CloudStorage/Dropbox/GitHub/MSSP/MSSP_HPYP.R", echo=TRUE)
